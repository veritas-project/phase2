{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veritas Fairness Assement - Life Insurance Underwriting Study (sample code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes samples of code used in the analysis conducted during the life insurance underwriting case study.\n",
    "\n",
    "It is applicable to insurance underwriting datasets including a life insurance dataset available on\n",
    "[kaggle](https://www.kaggle.com/c/prudential-life-insurance-assessment/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Written by Sankarshan Mridha (Swiss Re) and Laura Alvarez (Accenture) as an extension to Phase 1 Credit Scoring Use Case code https://github.com/veritas-project/phase1/tree/main/credit_scoring \n",
    "\n",
    "Contact email: Veritas@mas.gov.sg\n",
    "\n",
    "\n",
    "Copyright © 2021 Monetary Authority of Singapore\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use\n",
    "this file except in compliance with the License. You may obtain a copy of the\n",
    "License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed\n",
    "under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n",
    "CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
    "specific language governing permissions and limitations under the Licens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:57:07.454530Z",
     "start_time": "2021-06-04T04:57:05.895944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Core Packages\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, brier_score_loss, precision_score,\\\n",
    "recall_score, balanced_accuracy_score\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "SEED = 123\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:07:23.195352Z",
     "start_time": "2021-05-27T09:07:22.267496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our code (autoreload)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"../utils\")\n",
    "import utility as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:07:25.099735Z",
     "start_time": "2021-05-27T09:07:25.068155Z"
    }
   },
   "outputs": [],
   "source": [
    "# High-res plots\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:57.859020Z",
     "start_time": "2021-05-27T09:08:57.832160Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please modify the following cell to update dataset file path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:07:33.442425Z",
     "start_time": "2021-05-27T09:07:33.336553Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n",
    "\n",
    "med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\n",
    "all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n",
    "\n",
    "mapper = {\n",
    "    'Id': 'Insured ID',\n",
    "    'InsuredInfo_6': 'Gender',\n",
    "    'InsuredInfo_1': 'Race',\n",
    "    'InsuredInfo_4': 'Nationality',\n",
    "    'Family_Hist_1': 'Marital Status',\n",
    "    'InsuredInfo_3': 'Occupation Type',\n",
    "    'Employment_Info_2': 'Occupation Industry',\n",
    "    'Wt': 'Weight',\n",
    "    'Ht': 'Height',\n",
    "    'Medical_History_4': 'Smoker Status',\n",
    "    'Ins_Age': 'Age at Policy Inception',\n",
    "    'Insurance_History_3': 'No. of Life Policies',\n",
    "    'Insurance_History_2': 'No. of Accident Policies',\n",
    "    'Insurance_History_7': 'No. of CI Policies',\n",
    "    'Product_Info_3': 'Duration in force for Medical Plan'\n",
    "}\n",
    "\n",
    "all_data.rename(mapper=mapper, axis=1, inplace=True)\n",
    "# Drop columns we do not have confidence in mapping to\n",
    "drop_columns = ('Medical', 'Family', 'Insurance', 'Product', 'Employment', 'Insurance', 'InsuredInfo')\n",
    "mask = all_data.columns.str.startswith(drop_columns)\n",
    "all_data = all_data.iloc[:,~mask]\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "# 0: {1,2}\n",
    "# 1: {7,8}\n",
    "# -1: the rest\n",
    "all_data['Risk'] = pd.cut(all_data.Response, bins=[0,2,6,8], labels=[0,-1,1])\n",
    "all_data = all_data.astype({\"Risk\": int})\n",
    "all_data.Risk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Response = -1\n",
    "df = all_data.loc[all_data['Risk']!= -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train & test datasets\n",
    "columns_to_drop = ['Insured ID','Response','Risk', 'Nationality', 'Marital Status'] #droping race at pre-processing point \n",
    "X = df.drop(columns=columns_to_drop)\n",
    "X = X.astype({\"Occupation Industry\": object, \"Occupation Type\": object, \"Smoker Status\": object, \"Gender\": object})\n",
    "y = df['Risk']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "print(f\"X_train.shape: {X_train.shape}, X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}, y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create masks for Fairness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gender identifying mask\n",
    "gender_mask = (X_test[\"Gender\"] == 1)  # assuming 1: Male, 2: Female \n",
    "print('Percent Male:', round(np.mean(gender_mask), 5), 'Percent Female:', round(np.mean(~gender_mask), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a race identifying mask\n",
    "race_mask = (X_test[\"Race\"] == 1)  # assuming 1: Majority, 2: Other \n",
    "print('Percent Major:', round(np.mean(race_mask), 5), 'Percent Minor:', round(np.mean(~race_mask), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, selector(dtype_exclude=[\"object\", \"category\"])),\n",
    "    ('cat', categorical_transformer, selector(dtype_include=[\"object\", \"category\"]))\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train.drop(columns='Race'))# dropping race prior to preprocessor\n",
    "X_test_transformed = preprocessor.transform(X_test.drop(columns='Race'))# dropping race prior to preprocessor\n",
    "print(f\"X_train_transformed.shape: {X_train_transformed.shape}, X_test_transformed.shape: {X_test_transformed.shape}\")\n",
    "\n",
    "print(f\"Class distribution: {np.unique(y_train, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:03.409847Z",
     "start_time": "2021-05-27T09:08:03.378985Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model_baseline = joblib.load('model/model_baseline_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:16.718000Z",
     "start_time": "2021-05-27T09:08:16.637006Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict probabilites\n",
    "y_prob = model_baseline.predict_proba(X_test_transformed)[:,1]\n",
    "\n",
    "\n",
    "# compute AUC\n",
    "print(roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:07:12.498531Z",
     "start_time": "2021-06-04T04:07:11.959724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute classification metrics by 0.5 cutoff\n",
    "y_pred = np.where(y_prob > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:54:18.337418Z",
     "start_time": "2021-05-27T09:54:18.308745Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute ROC curve\n",
    "fpr, tpr, th = roc_curve(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:41:52.559735Z",
     "start_time": "2021-06-04T04:41:52.112781Z"
    }
   },
   "outputs": [],
   "source": [
    "# find optimal cutoff by max balanced accuracy\n",
    "ba = (tpr + (1 - fpr))/2\n",
    "best_ba = np.max(ba)\n",
    "best_th = th[np.argmax(ba)]\n",
    "best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T06:08:12.174816Z",
     "start_time": "2021-06-04T06:08:11.561509Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot balanced accuracy and approval rate vs threshold\n",
    "ba = 0.5*(tpr + 1 - fpr)\n",
    "base_ar = np.mean(y_test.astype(int))\n",
    "ar = base_ar*tpr + (1-base_ar)*fpr\n",
    "plt.plot(th, ba, label='balanced accuracy')\n",
    "plt.plot(th, ar, label='approval rate')\n",
    "plt.plot()\n",
    "plt.scatter(best_th, best_ba, c='r', marker='x', s=100, label='max bal acc')\n",
    "plt.xlabel('Underwriting Threshold')\n",
    "plt.title('Life Insurance Underwriting')\n",
    "plt.xlim((y_prob.min(), y_prob.max()))\n",
    "plt.legend(framealpha=0.3, facecolor='white', fontsize=12, loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T10:32:35.732444Z",
     "start_time": "2021-05-27T10:32:35.684272Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute classification metrics by optimal cutoff\n",
    "y_pred_ba = np.where(y_prob > best_th, 1, 0)\n",
    "print(classification_report(y_test, y_pred_ba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred_ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance\n",
    "Here we quantify the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code corresponding to section 2.7.3 Step 3: Build and Validate in Veritas Document 4 FEAT Principles Assessment Case Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T10:32:58.189075Z",
     "start_time": "2021-05-27T10:32:58.151013Z"
    }
   },
   "outputs": [],
   "source": [
    "test_bal_acc = metrics.balanced_accuracy_score(y_test, y_pred_ba)\n",
    "print(\"Balanced accuracy on test set {:.4f} at threshold {:.4f}\".format(test_bal_acc, best_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T05:03:40.507348Z",
     "start_time": "2021-06-04T05:03:40.269175Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred_ba)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_names)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:30.316274Z",
     "start_time": "2021-05-27T09:08:29.997811Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "def plot_roc(model, X, y):\n",
    "    figure = plt.figure(figsize=(5,5))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Random Chance', alpha=.8)\n",
    "    metrics.plot_roc_curve(model, X, y, name='model', alpha=0.3, lw=2, ax=plt.gca())\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=13)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(model_baseline, X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve with lines for gender subgroups\n",
    "def plot_roc(model, X, y):\n",
    "    figure = plt.figure(figsize=(5,5))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Random Chance', alpha=.8)\n",
    "    metrics.plot_roc_curve(model, X, y, name='model', alpha=0.3, lw=2, ax=plt.gca())\n",
    "    metrics.plot_roc_curve(model, X[gender_mask], y[gender_mask], name='Male', alpha=0.3, lw=2, ax=plt.gca())\n",
    "    metrics.plot_roc_curve(model, X[~gender_mask], y[~gender_mask], name='Female', alpha=0.3, lw=2, ax=plt.gca())\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=13)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(model_baseline, X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = metrics.roc_auc_score(y_test, y_prob)\n",
    "print(auc)\n",
    "auc_male = metrics.roc_auc_score(y_test[gender_mask], y_prob[gender_mask])\n",
    "print(auc_male)\n",
    "auc_female = metrics.roc_auc_score(y_test[~gender_mask], y_prob[~gender_mask])\n",
    "print(auc_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:38.975905Z",
     "start_time": "2021-05-27T09:08:38.394396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bootstrap uncertainty analysis\n",
    "\n",
    "# Metrics based on predictions\n",
    "prediction_metrics = {'True Positive Rate (i.e. sensitivity, or recall)': metrics.recall_score,\n",
    "                      'True Negative Rate (i.e. specificity)': lambda x, y: metrics.recall_score(x, y, pos_label=0),\n",
    "                      'Balanced Accuracy': metrics.balanced_accuracy_score,\n",
    "                      'Positive Predictive Value (precision)': metrics.precision_score}\n",
    "\n",
    "# Metrics based on probabilities\n",
    "probability_metrics = {'Area Under ROC': metrics.roc_auc_score}\n",
    "\n",
    "for name, metric_func in prediction_metrics.items():\n",
    "    print(name, \":\", utils.format_uncertainty(*utils.bootstrap_conf_int(y_test.values, y_pred_ba, metric_func, k=25)))\n",
    "\n",
    "for name, metric_func in probability_metrics.items():\n",
    "    print(name, \":\", utils.format_uncertainty(*utils.bootstrap_conf_int(y_test.values, y_prob, metric_func, k=25)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:42.409379Z",
     "start_time": "2021-05-27T09:08:41.988381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calibration curve\n",
    "def plot_calibration(bin_true_prob, bin_pred_prob):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], \"k:\", label=\"perfectly calibrated\")\n",
    "    ax1.plot(bin_pred_prob, bin_true_prob, \"s-\",\n",
    "             label=\"model\")\n",
    "\n",
    "    ax2.hist([y_prob[y_test == 1], y_prob[y_test == 0]], label=[\"healthy\", \"risky\"],\n",
    "              histtype='bar', stacked=True)\n",
    "\n",
    "    ax1.set_ylabel(\"Fraction of healthy applicants\", fontsize=14)\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.legend(loc=\"lower right\", fontsize=12)\n",
    "    ax1.set_title('Model Calibration (reliability curve)', fontsize=16)\n",
    "\n",
    "    ax2.set_xlabel(\"Model Output Probabilities (binned)\", fontsize=14)\n",
    "    ax2.set_ylabel(\"Count\", fontsize=14)\n",
    "    ax2.legend(loc=\"upper left\", ncol=2, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "bin_true_prob, bin_pred_prob = calibration_curve(y_test, y_prob, n_bins=10)\n",
    "plot_calibration(bin_true_prob, bin_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:09:48.782456Z",
     "start_time": "2021-05-27T09:09:30.439392Z"
    }
   },
   "outputs": [],
   "source": [
    "# run Isotonic calibration\n",
    "clf_isotonic = CalibratedClassifierCV(model_baseline, cv=3, method='isotonic')\n",
    "clf_isotonic = clf_isotonic.fit(X_train_transformed, y_train)\n",
    "model_baseline_iso = clf_isotonic.predict_proba(X_test_transformed)[:, 1]\n",
    "model_baseline_score = brier_score_loss(y_test, y_prob)\n",
    "clf_isotonic_score = brier_score_loss(y_test, model_baseline_iso)\n",
    "print(model_baseline_score, clf_isotonic_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As calibrated model has similar brier score, calibration is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness\n",
    "Here we compute some fairness metrics with respect to gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code corresponding to section 2.7.4 Part C – Measuring Disadvantage in Veritas Document 4 FEAT Principles Assessment Case Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_thresholds(y_prob, threshold_mask, th_A=0.5, th_B=0.5):\n",
    "    \"\"\"\n",
    "    Helper function to apply classification thresholds based on a mask\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        y_test::pd.DataFrame or similar: Ground truth Labels\n",
    "        y_probs::np.array or similar: Predicted test probabilities\n",
    "        threshold_mask::pd.Series or similar: Boolean array of the variable to apply the classification thresholds on\n",
    "        th_A::float: custom threshold for Group A, defaults to 0.5\n",
    "        th_B::float: customt hreshold for Group B, defaults to 0.5\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        y_pred::array: array of predicted classifications\n",
    "    \"\"\"\n",
    "    y_pred = np.zeros_like(y_prob)\n",
    "    y_pred[threshold_mask] = (y_prob[threshold_mask] >= th_A).astype(int)\n",
    "    y_pred[~threshold_mask] = (y_prob[~threshold_mask] >= th_B).astype(int)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_fairness(y_test, y_probs, variable_mask, th_A=0.5, th_B=0.5, verbose=True):\n",
    "    \"\"\"\n",
    "    Helper function to evaluate group fairness given custom thresholds\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        y_test::pd.DataFrame or similar: Ground truth Labels\n",
    "        y_probs::np.array or similar: Predicted test probabilities\n",
    "        variable_mask::pd.Series or similar: Boolean array of the variable to evaluate group fairness on\n",
    "        th_A::float: custom threshold for Group A, defaults to 0.5\n",
    "        th_B::float: customt hreshold for Group B, defaults to 0.5\n",
    "        verbose::bool: \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        fairness_metrics::dict: dictionary of computed fairness metrics\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    # Run and store fairness analysis\n",
    "    analysis = utils.FairnessAnalysis(y_test.astype(int), y_probs, variable_mask)\n",
    "    metrics = analysis.compute(th_A, th_B)\n",
    "    for attr, name in utils.FairnessAnalysis.metric_names.items():\n",
    "        metric = round(getattr(metrics, attr), 3)\n",
    "        if verbose:\n",
    "            print(f\"{name}: {metric}\")\n",
    "        d[name] = metric\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_performance_metrics(y_true, y_probs, variable_mask, th_A=0.5, th_B=0.5,Group_1mask='Group_a',Group_0mask='Group_b'):\n",
    "    \"\"\"\n",
    "    Helper function to evaluate group rates given custom thresholds\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        y_true::pd.DataFrame or similar: Ground truth Labels\n",
    "        y_probs::np.array or similar: Predicted test probabilities\n",
    "        variable_mask::pd.Series or similar: Boolean array of the variable to evaluate group fairness on\n",
    "        th_A::float: custom threshold for Group A, defaults to 0.5\n",
    "        th_B::float: customt hreshold for Group B, defaults to 0.5\n",
    "        verbose::bool: \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        performance_metrics::df: dataframe of computed performance metrics per group\n",
    "    \"\"\"\n",
    "\n",
    "    # Run and store performance metrics per group\n",
    "    analysis = utils.FairnessAnalysis(y_true.astype(int), y_probs, variable_mask)\n",
    "    perf_metrics = analysis.compute_performance_rates(th_A,th_B)\n",
    "    perf_metrics.rename(columns={'Group_a': Group_1mask, 'Group_b': Group_0mask}, inplace=True)\n",
    "    return perf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fairness analysis\n",
    "race_analysis = utils.FairnessAnalysis(y_test.astype(int), y_prob, race_mask)\n",
    "race_metrics = race_analysis.compute(best_th)\n",
    "for attr, name in utils.FairnessAnalysis.metric_names.items():\n",
    "    print(name, \":\", round(getattr(race_metrics, attr), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:40:56.021857Z",
     "start_time": "2021-06-04T08:40:55.637228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bootstrap Uncertainty\n",
    "bs_metrics = []\n",
    "np.random.seed(0)\n",
    "for i in range(25):\n",
    "    idx = np.random.choice(len(y_test), len(y_test), replace=True)\n",
    "    tmp = utils.FairnessAnalysis(y_test.astype(int).values[idx], y_prob[idx], race_mask.values[idx])\n",
    "    tmp2 = tmp.compute(best_th)\n",
    "    bs_metrics.append(tmp2)\n",
    "\n",
    "bs_metrics = np.array(bs_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:40:56.740266Z",
     "start_time": "2021-06-04T08:40:56.698049Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, attr in enumerate(race_metrics._fields):\n",
    "    print(utils.FairnessAnalysis.metric_names[attr], \":\", \n",
    "          utils.format_uncertainty(bs_metrics[:, i].mean(), 2 * bs_metrics[:, i].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_rates_race_best_th = group_performance_metrics(y_test, y_prob, race_mask, th_A=best_th, th_B=best_th,Group_1mask='Chinese', Group_0mask='Others')\n",
    "perform_rates_race_best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_rates_race_default_th = group_performance_metrics(y_test, y_prob, race_mask, th_A=0.5, th_B=0.5,Group_1mask='Chinese', Group_0mask='Others')\n",
    "perform_rates_race_default_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance-Fairness Tradeoffs\n",
    "Here we explore fairness-performance tradeoffs stemming from our choice of lending threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code corresponding to section 2.7.4 Part C – Measuring Disadvantage in Veritas Document 4 FEAT Principles Assessment Case Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the protected feature of race, the performance-fairness tradeoff analysis below was run for illustrative purposes only, as no mitigation is required (FNR ratio observed is 0.987 +/- 0.172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:41:18.640078Z",
     "start_time": "2021-06-04T08:41:18.601376Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Best Balanced Accuracy (single): {best_ba:.5f} with TH: {best_th:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_mitigation(y_test, y_probs, variable_mask, variable_metrics, verbose=True):\n",
    "    \"\"\"\n",
    "    Helper function to evaluate group fairness in a one-vs-rest manner.\n",
    "    \n",
    "    Group A refers to `col`; Group B refers to excluding `col`\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        y_test::pd.DataFrame or similar: Ground truth Labels\n",
    "        y_probs::np.array or similar: Predicted test probabilities\n",
    "        variable_mask::pd.Series or similar: Boolean array of the variable to evaluate group fairness on\n",
    "        verbose::bool: \n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        Tuple of: \n",
    "            split_sweep::named tuples: Group Metrics computed for a grid of th_a, th_b\n",
    "            th_a::np.array: grid used to compute th_a\n",
    "            th_b::np.array: grid used to compute th_b\n",
    "            best_con_th_a::float: best constrainted threshold for group A\n",
    "            best_con_th_b::float: best constrainted threshold for group B\n",
    "        fairness_metrics::dict: dictionary of computed fairness metrics\n",
    "    \"\"\"\n",
    "    # Run fairness analysis and tune grid to find best thresholds\n",
    "    analysis = utils.FairnessAnalysis(y_test.astype(int), y_probs, variable_mask)\n",
    "    th_a = np.linspace(0.3, 0.7, 500)\n",
    "    th_b = np.linspace(0.3, 0.7, 500)\n",
    "    grid_th_a, grid_th_b = np.meshgrid(th_a, th_b, sparse=True)\n",
    "    metrics_split_sweep = analysis.compute(grid_th_a, grid_th_b)\n",
    "    \n",
    "    bal_acc_grid = metrics_split_sweep.bal_acc\n",
    "    idx = np.unravel_index(bal_acc_grid.argmax(), bal_acc_grid.shape)\n",
    "    best_th_a, best_th_b = th_a[idx[1]], th_b[idx[0]]\n",
    "    if verbose:\n",
    "        name = variable_mask.name if isinstance(variable_mask, pd.Series) else 'A'\n",
    "        print(f\"Best Balanced Accuracy (split): {bal_acc_grid.max():.5f} with {name}-majority TH: {best_th_a:.3f}, {name}-minority TH: {best_th_b:.3f}\")\n",
    "\n",
    "    # Find bal accuracy when fairness constrained to 4/5th threshold\n",
    "    constrained_bal_acc = np.copy(bal_acc_grid)\n",
    "    if variable_metrics.fnr_ratio<1:\n",
    "        constrained_bal_acc[np.where(np.absolute(metrics_split_sweep.fnr_ratio) < 0.8)] = 0\n",
    "    else:\n",
    "        constrained_bal_acc[np.where(np.absolute(metrics_split_sweep.fnr_ratio) > 1.2)] = 0\n",
    "\n",
    "    idx = np.unravel_index(constrained_bal_acc.argmax(), constrained_bal_acc.shape)\n",
    "    best_con_th_a, best_con_th_b = th_a[idx[1]], th_b[idx[0]]\n",
    "    if verbose:\n",
    "        name = variable_mask.name if isinstance(variable_mask, pd.Series) else 'A'\n",
    "        print(f\"Best Fairness-Constrained Balanced Accuracy: {constrained_bal_acc.max():.5f} with {name}-majority TH: {best_con_th_a:.3f}, {name}-minority TH: {best_con_th_b:.3f}\")\n",
    "    \n",
    "    return (metrics_split_sweep, th_a, th_b, best_th_a, best_th_b, best_con_th_a, best_con_th_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_metrics = postprocess_mitigation(y_test, y_prob, race_mask, race_metrics)\n",
    "race_split_sweep, th_a, th_b, best_th_a, best_th_b, best_con_th_a, best_con_th_b = race_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:39:00.849155Z",
     "start_time": "2021-06-04T04:38:59.653430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(9,8))\n",
    "plt.title('Fairness vs. Performance Tradeoffs', fontsize=18)\n",
    "plt.xlabel('Approval Threshold Men', fontsize=16)\n",
    "plt.ylabel('Approval Threshold Women', fontsize=16)\n",
    "plt.xlim(np.min(th_a), np.max(th_a))\n",
    "plt.ylim(np.min(th_b), np.max(th_b))\n",
    "\n",
    "bal_acc_lns = plt.contourf(th_a, th_b, race_split_sweep.bal_acc, levels=20)\n",
    "\n",
    "eo_lns = plt.contour(th_a, th_b, race_split_sweep.fnr_ratio, colors='white', levels=[0.4,0.8, 1,1.2, 2,  4, 6, 10,12])\n",
    "eo_lns.collections[-1].set_label('FNR Ratio')\n",
    "\n",
    "cbar = plt.colorbar(bal_acc_lns)\n",
    "cbar.set_label('Model Performance (balanced accuracy)', fontsize=14)\n",
    "plt.clabel(eo_lns, inline=1,fmt='%1.2f', fontsize=14)\n",
    "\n",
    "# Mark maximums\n",
    "# plt.plot([0, 1], [0, 1], c='gray', ls=':', label='single threshold')\n",
    "plt.scatter(best_th_a, best_th_b, c='b', marker='d', s=100, label= 'max bal acc', zorder=2)\n",
    "plt.scatter(best_th, best_th, c='r', marker='x', s=100, label= 'single TH bal acc', zorder=2)\n",
    "plt.scatter(best_con_th_a, best_con_th_b, c='purple', marker='*', s=100, label= 'FNR bal acc', zorder=2)\n",
    "lgnd = plt.legend(framealpha=0.3, facecolor='black', fontsize=12, loc='lower right')\n",
    "for text in lgnd.get_texts():\n",
    "    text.set_color(\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices, classification report and other metrics after mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_split_th = group_fairness(y_test, y_prob, race_mask, th_A=best_th_a, th_B=best_th_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_split_th = group_thresholds(y_prob, race_mask, best_th_a, best_th_b, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_split_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_rates_split_th = group_performance_metrics(y_test, y_prob, race_mask, th_A=best_th_a, th_B=best_th_b,Group_1mask='Chinese', Group_0mask='Others')\n",
    "perform_rates_split_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mit = group_thresholds(y_prob, race_mask, best_con_th_a, best_con_th_b, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_mit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix after mitigation - overall\n",
    "cf_matrix_mit = confusion_matrix(y_test, y_pred_mit) \n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix_mit.flatten()]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_names)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix_mit, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix after mitigation - Chinese\n",
    "cf_matrix_mit_chinese = confusion_matrix(y_test[race_mask], y_pred_mit[race_mask]) \n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix_mit_chinese.flatten()]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_names)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix_mit_chinese, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix after mitigation - Others\n",
    "cf_matrix_mit_others = confusion_matrix(y_test[~race_mask], y_pred_mit[~race_mask]) \n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix_mit_others.flatten()]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts,group_names)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix_mit_others, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_mit = group_fairness(y_test, y_prob, race_mask, th_A=best_con_th_a, th_B=best_con_th_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_rates_mit = group_performance_metrics(y_test, y_prob, race_mask, th_A=best_con_th_a, th_B=best_con_th_b,Group_1mask='Chinese', Group_0mask='Others')\n",
    "perform_rates_mit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of post-processing mitigation for race on gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the thresholds optimised for fairness with respect to i.e. race \n",
    "# Investigate the effect of applying these thresholds on a different protected feature i. gender\n",
    "    #(1) Apply thresholds optimised for fairness for race - using race mask\n",
    "    #(2) Calculate fairness metrics - using gender mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness Analysis for race before mitigation for gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fairness analysis\n",
    "gender_analysis = utils.FairnessAnalysis(y_test.astype(int), y_prob, gender_mask)\n",
    "gender_metrics = gender_analysis.compute(best_th)\n",
    "for attr, name in utils.FairnessAnalysis.metric_names.items():\n",
    "    print(name, \":\", round(getattr(gender_metrics, attr), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness Analysis for gender after mitigation for race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_mitigation_gender_analysis = utils.FairnessAnalysisSecondary(y_test.astype(int), y_prob, race_mask, best_con_th_a,best_con_th_b)\n",
    "race_mitigation_gender_metrics = race_mitigation_gender_analysis.compute_secondary(gender_mask)\n",
    "for attr, name in utils.FairnessAnalysisSecondary.metric_names.items():\n",
    "    print(name, \":\", round(getattr(race_mitigation_gender_metrics, attr), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puw",
   "language": "python",
   "name": "puw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
