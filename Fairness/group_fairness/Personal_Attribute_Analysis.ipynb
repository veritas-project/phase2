{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veritas Fairness Assement - Life Insurance Underwriting Study (sample code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes samples of code used in the analysis conducted during the life insurance underwriting case study.\n",
    "\n",
    "It is applicable to insurance underwriting datasets including a life insurance dataset available on\n",
    "[kaggle](https://www.kaggle.com/c/prudential-life-insurance-assessment/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Written by Sankarshan Mridha (Swiss Re) and Laura Alvarez (Accenture) as an extension to Phase 1 Credit Scoring Use Case code https://github.com/veritas-project/phase1/tree/main/credit_scoring \n",
    "\n",
    "Contact email: Veritas@mas.gov.sg\n",
    "\n",
    "\n",
    "Copyright Â© 2021 Monetary Authority of Singapore\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use\n",
    "this file except in compliance with the License. You may obtain a copy of the\n",
    "License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed\n",
    "under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n",
    "CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
    "specific language governing permissions and limitations under the Licens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:57:07.454530Z",
     "start_time": "2021-06-04T04:57:05.895944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Core Packages\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "import phik\n",
    "from phik import resources, report\n",
    "from phik.report import plot_correlation_matrix\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:07:23.195352Z",
     "start_time": "2021-05-27T09:07:22.267496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our code (autoreload)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"../utils\")\n",
    "import utility as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:07:25.099735Z",
     "start_time": "2021-05-27T09:07:25.068155Z"
    }
   },
   "outputs": [],
   "source": [
    "# High-res plots\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:57.859020Z",
     "start_time": "2021-05-27T09:08:57.832160Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please modify the following cell to update dataset file path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n",
    "\n",
    "med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\n",
    "all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n",
    "\n",
    "mapper = {\n",
    "    'Id': 'Insured ID',\n",
    "    'InsuredInfo_6': 'Gender',\n",
    "    'InsuredInfo_1': 'Race',\n",
    "    'InsuredInfo_4': 'Nationality',\n",
    "    'Family_Hist_1': 'Marital Status',\n",
    "    'InsuredInfo_3': 'Occupation Type',\n",
    "    'Employment_Info_2': 'Occupation Industry',\n",
    "    'Wt': 'Weight',\n",
    "    'Ht': 'Height',\n",
    "    'Medical_History_4': 'Smoker Status',\n",
    "    'Ins_Age': 'Age at Policy Inception',\n",
    "    'Insurance_History_3': 'No. of Life Policies',\n",
    "    'Insurance_History_2': 'No. of Accident Policies',\n",
    "    'Insurance_History_7': 'No. of CI Policies',\n",
    "    'Product_Info_3': 'Duration in force for Medical Plan'\n",
    "}\n",
    "\n",
    "all_data.rename(mapper=mapper, axis=1, inplace=True)\n",
    "# Drop columns we do not have confidence in mapping to\n",
    "drop_columns = ('Medical', 'Family', 'Insurance', 'Product', 'Employment', 'Insurance', 'InsuredInfo')\n",
    "mask = all_data.columns.str.startswith(drop_columns)\n",
    "all_data = all_data.iloc[:,~mask]\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.astype({\"Occupation Industry\": object, \"Occupation Type\": object, \"Smoker Status\": object, \"Gender\": object, \\\n",
    "             \"Nationality\": object, \"Marital Status\":object, \"Race\":object})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "# 0: {1,2}\n",
    "# 1: {7,8}\n",
    "# -1: the rest\n",
    "all_data['Risk'] = pd.cut(all_data.Response, bins=[0,2,6,8], labels=[0,-1,1])\n",
    "all_data = all_data.astype({\"Risk\": int})\n",
    "all_data.Risk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Response = -1\n",
    "df = all_data.loc[all_data['Risk']!= -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train & test datasets\n",
    "columns_to_drop = ['Insured ID','Response','Risk']  \n",
    "X = df.drop(columns=columns_to_drop)\n",
    "y = df['Risk']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "print(f\"X_train.shape: {X_train.shape}, X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}, y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create masks for Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gender identifying mask\n",
    "gender_mask = (X_test[\"Gender\"] == 1)  # assuming 1: Male, 2: Female \n",
    "print('Percent Male:', round(np.mean(gender_mask), 5), 'Percent Female:', round(np.mean(~gender_mask), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a race identifying mask\n",
    "race_mask = (X_test[\"Race\"] == 1)  # assuming 1: Majority, 2: Other \n",
    "print('Percent Major:', round(np.mean(race_mask), 5), 'Percent Other:', round(np.mean(~race_mask), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, selector(dtype_exclude=[\"object\", \"category\"])),\n",
    "    ('cat', categorical_transformer, selector(dtype_include=[\"object\", \"category\"]))\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "print(f\"X_train_transformed.shape: {X_train_transformed.shape}, X_test_transformed.shape: {X_test_transformed.shape}\")\n",
    "\n",
    "print(f\"Class distribution: {np.unique(y_train, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features names from transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_preprocessor_c=list(preprocessor.named_transformers_['cat'].get_feature_names())\n",
    "features_preprocessor_n=preprocessor.transformers_[0][2]\n",
    "features_preprocessor_all=features_preprocessor_n+features_preprocessor_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:03.409847Z",
     "start_time": "2021-05-27T09:08:03.378985Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model containing personal attributes\n",
    "model_all_v = joblib.load('model/model_all_variables_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:08:16.718000Z",
     "start_time": "2021-05-27T09:08:16.637006Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict probabilites\n",
    "y_prob = model_all_v.predict_proba(X_test_transformed)[:,1]\n",
    "\n",
    "\n",
    "# compute AUC\n",
    "print(roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:07:12.498531Z",
     "start_time": "2021-06-04T04:07:11.959724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute classification metrics by 0.5 cutoff\n",
    "y_pred = np.where(y_prob > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:54:18.337418Z",
     "start_time": "2021-05-27T09:54:18.308745Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute ROC curve\n",
    "fpr, tpr, th = roc_curve(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:41:52.559735Z",
     "start_time": "2021-06-04T04:41:52.112781Z"
    }
   },
   "outputs": [],
   "source": [
    "# find optimal cutoff by max balanced accuracy\n",
    "ba = (tpr + (1 - fpr))/2\n",
    "best_ba = np.max(ba)\n",
    "best_th = th[np.argmax(ba)]\n",
    "best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T10:32:35.732444Z",
     "start_time": "2021-05-27T10:32:35.684272Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute classification metrics by optimal cutoff\n",
    "y_pred_ba = np.where(y_prob > best_th, 1, 0)\n",
    "print(classification_report(y_test, y_pred_ba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness\n",
    "Here we compute some fairness metrics with respect to gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code corresponding to section 2.7.4 Part C â Measuring Disadvantage in Veritas Document 4 FEAT Principles Assessment Case Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T09:09:48.847168Z",
     "start_time": "2021-05-27T09:09:48.785381Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:40:25.745652Z",
     "start_time": "2021-06-04T08:40:24.867214Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run fairness analysis\n",
    "gender_analysis = utils.FairnessAnalysis(y_test.astype(int), y_prob, gender_mask)\n",
    "gender_metrics = gender_analysis.compute(best_th)\n",
    "for attr, name in utils.FairnessAnalysis.metric_names.items():\n",
    "    print(name, \":\", round(getattr(gender_metrics, attr), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:40:56.021857Z",
     "start_time": "2021-06-04T08:40:55.637228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bootstrap Uncertainty\n",
    "bs_metrics = []\n",
    "np.random.seed(0)\n",
    "for i in range(25):\n",
    "    idx = np.random.choice(len(y_test), len(y_test), replace=True)\n",
    "    tmp = utils.FairnessAnalysis(y_test.astype(int).values[idx], y_prob[idx], gender_mask.values[idx])\n",
    "    tmp2 = tmp.compute(best_th)\n",
    "    bs_metrics.append(tmp2)\n",
    "\n",
    "bs_metrics = np.array(bs_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:40:56.740266Z",
     "start_time": "2021-06-04T08:40:56.698049Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, attr in enumerate(gender_metrics._fields):\n",
    "    print(utils.FairnessAnalysis.metric_names[attr], \":\", \n",
    "          utils.format_uncertainty(bs_metrics[:, i].mean(), 2 * bs_metrics[:, i].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Attributes\n",
    "Here we consider how we might justify the inclusion of personal attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code corresponding to section 2.7.2.2 Part D: Justify the Use of Personal Attributes in Veritas Document 4 FEAT Principles Assessment Case Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T04:44:56.441380Z",
     "start_time": "2021-06-04T04:44:56.005371Z"
    }
   },
   "outputs": [],
   "source": [
    "personal_attrs = ['Gender', 'Race', 'Nationality', 'Marital Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, selector(dtype_exclude=[\"object\", \"category\"])),\n",
    "    ('cat', categorical_transformer, selector(dtype_include=[\"object\", \"category\"]))\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T06:25:16.437851Z",
     "start_time": "2021-06-09T06:24:14.612844Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leave one out analysis\n",
    "loo_metrics_gender = []\n",
    "model_loo = LogisticRegression(max_iter=150, random_state=SEED)\n",
    "for i, attr in enumerate(personal_attrs):\n",
    "    print('\\nTraining model without:', attr)\n",
    "    X_train_transformed_loo = preprocessor.fit_transform(X_train.drop([attr], axis=1))\n",
    "    X_test_transformed_loo = preprocessor.transform(X_test.drop([attr], axis=1))\n",
    "\n",
    "    model_loo.fit(X_train_transformed_loo, y_train)\n",
    "    \n",
    "    # Predict and compute fairness Metrics\n",
    "    loo_test_probs = model_loo.predict_proba(X_test_transformed_loo)[:,1]\n",
    "    loo_analysis = utils.FairnessAnalysis(y_test.astype(int).values, loo_test_probs, gender_mask)\n",
    "    loo_metrics_gender.append(loo_analysis.compute(best_th))\n",
    "    \n",
    "    # Display results as they arrive\n",
    "    for field, name in utils.FairnessAnalysis.metric_names.items():\n",
    "        print(name, \":\", round(getattr(loo_metrics_gender[i], field), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T06:08:55.046968Z",
     "start_time": "2021-06-04T06:08:55.006487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute difference (removed - included)\n",
    "bal_acc_deltas = [loo.bal_acc - gender_metrics.bal_acc for loo in loo_metrics_gender]\n",
    "fnr_par_deltas = [loo.fnr_parity - gender_metrics.fnr_parity for loo in loo_metrics_gender]\n",
    "fnr_rat_deltas = [loo.fnr_ratio - gender_metrics.fnr_ratio for loo in loo_metrics_gender]\n",
    "fpr_rat_deltas = [loo.fpr_ratio - gender_metrics.fpr_ratio for loo in loo_metrics_gender]\n",
    "fpr_par_deltas = [loo.fpr_parity - gender_metrics.fpr_parity for loo in loo_metrics_gender]\n",
    "equal_opp_deltas = [loo.equal_opp - gender_metrics.equal_opp for loo in loo_metrics_gender]\n",
    "\n",
    "fnr_loo = [loo.fnr_parity for loo in loo_metrics_gender]\n",
    "fnr_rat_loo = [loo.fnr_ratio for loo in loo_metrics_gender]\n",
    "fpr_rat_loo = [loo.fpr_ratio for loo in loo_metrics_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T06:09:01.455946Z",
     "start_time": "2021-06-04T06:09:01.137791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc.')\n",
    "rects2 = plt.bar(x + width/2, fnr_par_deltas, width, label='FNR Parity (gender)')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(-gender_metrics.fnr_parity, c='k', ls=':', label='Neutral FNR Parity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - included)', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Fairness metrics based on Ratios\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc. Delta')\n",
    "rects2 = plt.bar(x + width/2, fnr_rat_loo, width, label='FNR Ratio (Gender) - LOO')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(gender_metrics.fnr_ratio, c='k', ls=':', label='FNR Ratio (Gender) ')\n",
    "plt.axhline(1.0, c='k', ls='-', lw='2', label='FNR Parity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - baseline)', fontsize=16)\n",
    "plt.legend(fontsize=12,loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc.')\n",
    "rects2 = plt.bar(x + width/2, equal_opp_deltas, width, label='Equal Opportunity (gender)')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(-gender_metrics.equal_opp, c='k', ls=':', label='Equal Opportunity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - included)', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Fairness metrics based on Ratios\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc. Delta')\n",
    "rects2 = plt.bar(x + width/2, fpr_rat_loo, width, label='FPR Ratio (Gender) - LOO')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(gender_metrics.fpr_ratio, c='k', ls=':', label='FPR Ratio (Gender) ')\n",
    "plt.axhline(1.0, c='k', ls='-', lw='2', label='FPR Parity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - baseline)', fontsize=16)\n",
    "plt.legend(fontsize=12,loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc.')\n",
    "rects2 = plt.bar(x + width/2, fpr_par_deltas, width, label='False Positive Rate Parity (gender)')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(-gender_metrics.fpr_parity, c='k', ls=':', label='FPR Parity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - baseline)', fontsize=16)\n",
    "plt.legend(fontsize=12, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justifying the use of Personal Attributes\n",
    "After running a \"leave-one-out\" feature removal analysis, we can assess the approximate impact of personal attributes on both fairness and model performance. We plot the impact of removing each personal attribute on the model's performance (balanced accuracy) and different fairness metric with respect to gender. We want balanced accuracy to be as high a possible, while ideally false negative rate ratio would be at neutrality. \n",
    "\n",
    "**Tradeoffs to be further examined**: Attributes for which removal negatively affect model performance but positively affect the fairness metric(s) of interest (or vice-versa). \n",
    "\n",
    "**Evidence for inclusion**: Attributes for which removal negatively affect both model performance and the fairness metric(s) of interest. \n",
    "\n",
    "**Evidence for exclusion**: Attributes for which removal positively affect both model performance and the fairness metric(s) of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T07:30:35.984376Z",
     "start_time": "2021-06-04T07:30:35.559187Z"
    }
   },
   "source": [
    "### Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order features by perm importance and plot \n",
    "# for model containing all personal attributes\n",
    "perm_importance = permutation_importance(model_all_v, X_train_transformed.toarray(), y_train, n_repeats=10,random_state=0)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array=np.array(features_preprocessor_all)#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,12)) \n",
    "plt.barh(features_array[sorted_idx], perm_importance.importances_mean[sorted_idx],color ='#FF9933')\n",
    "plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation and plot for numerical features\n",
    "corr_num = df.select_dtypes(exclude=object).corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,17))\n",
    "sns.heatmap(corr_num, xticklabels=corr_num.columns, yticklabels=corr_num.columns, ax=ax, cmap='RdGy', annot=True,\n",
    "            fmt='.2f', square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations Phik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_phik = df.phik_matrix()\n",
    "fig, ax = plt.subplots(figsize=(20,17))\n",
    "sns.heatmap(corr_phik, xticklabels=corr_phik.columns, yticklabels=corr_phik.columns, ax=ax, cmap=\"YlGnBu\", annot=True,\n",
    "            fmt='.2f', square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,15))\n",
    "sns.heatmap(df.significance_matrix(), xticklabels=corr_phik.columns, yticklabels=corr_phik.columns, ax=ax, cmap=\"YlGnBu\", annot=True,\n",
    "            fmt='.2f', square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_correlation, global_labels = X_train.global_phik()\n",
    "for c, l in zip(global_correlation, global_labels):\n",
    "    print(l, c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(global_correlation, x_labels=[''], y_labels=global_labels, \n",
    "                        vmin=0, vmax=1, figsize=(3.5,4),\n",
    "                        color_map='Blues', title=r'$g_k$',\n",
    "                        fontsize_factor=1.0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T06:04:18.820004Z",
     "start_time": "2021-06-09T06:04:17.536479Z"
    }
   },
   "source": [
    "## Race Fairness (major vs other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code corresponding to section 2.7.4 Part C â Measuring Disadvantage in Veritas Document 4 FEAT Principles Assessment Case Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T06:09:49.727989Z",
     "start_time": "2021-06-09T06:09:49.212118Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run race analysis, side-by-side with gender analysis\n",
    "race_analysis = utils.FairnessAnalysis(y_test.astype(int), y_prob, race_mask)\n",
    "race_metrics = race_analysis.compute(best_th)\n",
    "for attr, name in utils.FairnessAnalysis.metric_names.items():\n",
    "    print(name, \":\", round(getattr(race_metrics, attr), 3), \" | \", round(getattr(gender_metrics, attr), 3),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T06:10:31.311941Z",
     "start_time": "2021-06-09T06:10:30.906528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bootstrap Uncertainty\n",
    "bs_metrics = []\n",
    "np.random.seed(0)\n",
    "for i in range(25):\n",
    "    idx = np.random.choice(len(y_test), len(y_test), replace=True)\n",
    "    tmp = utils.FairnessAnalysis(y_test.astype(int).values[idx], y_prob[idx], race_mask.values[idx])\n",
    "    tmp2 = tmp.compute(best_th)\n",
    "    bs_metrics.append(tmp2)\n",
    "\n",
    "bs_metrics = np.array(bs_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T06:10:43.053594Z",
     "start_time": "2021-06-09T06:10:43.007403Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, attr in enumerate(race_metrics._fields):\n",
    "    print(utils.FairnessAnalysis.metric_names[attr], \":\", \n",
    "          utils.format_uncertainty(bs_metrics[:, i].mean(), 2 * bs_metrics[:, i].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal Attributes\n",
    "Here we consider how we might justify the inclusion of personal attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Code corresponding to section 2.7.2.2 Part D: Justify the Use of Personal Attributes in Veritas Document 4 FEAT Principles Assessment Case Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:05:23.695993Z",
     "start_time": "2021-06-18T09:04:36.160336Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leave one out analysis\n",
    "loo_metrics = []\n",
    "model_loo = LogisticRegression(max_iter=150, random_state=SEED)\n",
    "for i, attr in enumerate(personal_attrs):\n",
    "    print('\\nTraining model without:', attr)\n",
    "    X_train_transformed_loo = preprocessor.fit_transform(X_train.drop([attr], axis=1))\n",
    "    X_test_transformed_loo = preprocessor.transform(X_test.drop([attr], axis=1))\n",
    "\n",
    "    model_loo.fit(X_train_transformed_loo, y_train)\n",
    "    \n",
    "    # Predict and compute fairness Metrics\n",
    "    loo_test_probs = model_loo.predict_proba(X_test_transformed_loo)[:,1]\n",
    "    loo_analysis = utils.FairnessAnalysis(y_test.astype(int).values, loo_test_probs, race_mask)\n",
    "    loo_metrics.append(loo_analysis.compute(best_th))\n",
    "    \n",
    "    # Display results as they arrive\n",
    "    for field, name in utils.FairnessAnalysis.metric_names.items():\n",
    "        print(name, \":\", round(getattr(loo_metrics[i], field), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:05:23.754317Z",
     "start_time": "2021-06-18T09:05:23.699463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute difference (removed - included)\n",
    "bal_acc_deltas = [loo.bal_acc - race_metrics.bal_acc for loo in loo_metrics]\n",
    "fnr_par_deltas = [loo.fnr_parity - race_metrics.fnr_parity for loo in loo_metrics]\n",
    "fnr_rat_deltas = [loo.fnr_ratio - race_metrics.fnr_ratio for loo in loo_metrics]\n",
    "fpr_rat_deltas = [loo.fpr_ratio - race_metrics.fpr_ratio for loo in loo_metrics]\n",
    "fpr_par_deltas = [loo.fpr_parity - race_metrics.fpr_parity for loo in loo_metrics]\n",
    "equal_opp_deltas = [loo.equal_opp - race_metrics.equal_opp for loo in loo_metrics]\n",
    "\n",
    "fnr_loo = [loo.fnr_parity for loo in loo_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:08:36.047831Z",
     "start_time": "2021-06-18T09:08:35.791625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc.')\n",
    "rects2 = plt.bar(x + width/2, fnr_par_deltas, width, label='FNR Parity (race)')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(-race_metrics.fnr_parity, c='k', ls=':', label='Neutral FNR Parity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - included)', fontsize=16)\n",
    "plt.legend(fontsize=12, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fairness Metrics based on Ratios\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc. Delta')\n",
    "#rects2 = plt.bar(x + width/2, fnr_par_deltas, width, label='FNR Parity (gender)')\n",
    "rects2 = plt.bar(x + width/2, fnr_rat_loo, width, label='FNR Ratio (Race) - LOO')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(race_metrics.fnr_ratio, c='k', ls=':', label='FNR Ratio (Race) ')\n",
    "plt.axhline(1.0, c='k', ls='-', lw='2', label='FNR Parity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - baseline)', fontsize=16)\n",
    "plt.legend(fontsize=12,loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc.')\n",
    "rects2 = plt.bar(x + width/2, equal_opp_deltas, width, label='Equal Opportunity (race)')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(-race_metrics.equal_opp, c='k', ls=':', label='Neutral Equal Opportunity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - included)', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Impact of Personal Attributes', fontsize=18)\n",
    "x = np.arange(len(personal_attrs))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "rects1 = plt.bar(x - width/2, bal_acc_deltas, width, label='Balanced Acc.')\n",
    "rects2 = plt.bar(x + width/2, fpr_par_deltas, width, label='False Positive Rate Parity (race)')\n",
    "plt.axhline(0, c='k', ls='-', lw='1')\n",
    "plt.axhline(-race_metrics.fpr_parity, c='k', ls=':', label='Neutal FPR Parity') # show neutrality\n",
    "plt.xticks(x, personal_attrs, rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Effect of Removal (removed - baseline)', fontsize=16)\n",
    "plt.legend(fontsize=12,loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justifying the use of Personal Attributes\n",
    "After running a \"leave-one-out\" feature removal analysis, we can assess the approximate impact of personal attributes on both fairness and model performance. We plot the impact of removing each personal attribute on the model's performance (balanced accuracy) and different fairness metric with respect to gender. We want balanced accuracy to be as high a possible, while ideally false negative rate ratio would be at neutrality. \n",
    "\n",
    "**Tradeoffs to be further examined**: Attributes for which removal negatively affect model performance but positively affect the fairness metric(s) of interest (or vice-versa). \n",
    "\n",
    "**Evidence for inclusion**: Attributes for which removal negatively affect both model performance and the fairness metric(s) of interest. \n",
    "\n",
    "**Evidence for exclusion**: Attributes for which removal positively affect both model performance and the fairness metric(s) of interest. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puw",
   "language": "python",
   "name": "puw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
